BlockIQA: Local Sensitivity-Enhanced Blind Image Quality Assessment through Deep Block Analysis

Introduction
In the field of blind image quality assessment, accurately capturing localized distortions and structural inconsistencies within images remains a significant challenge. To tackle this issue, we propose BlockIQA, a novel framework that enhances local sensitivity through deep block analysis. BlockIQA divides images into non-overlapping blocks and employs a multi-branch architecture that integrates ResNet50, the Feature Pyramid Network, and an Auxiliary Feature Extraction Layer. The primary innovations of this paper include: (1) Segmenting images into smaller blocks for detailed analysis and employing a Gaussian similarity model that dynamically adapts to variations in feature dimensions and directional consistency. This approach enables more precise characterization of local image features. (2) Achieving a balance between global semantic information and localized distortion patterns through multiscale feature fusion using feature pyramid networks and auxiliary feature extraction layer. This ensures that while capturing overall image semantics, no fine local distortion information is overlooked. Experimental results demonstrate that BlockIQA performs well across datasets with various types of distortions and exhibits strong generalizability across different databases. In summary, BlockIQA pioneers a new deep learning architectural paradigm for blind image quality assessment. Its design philosophy of enhancing local sensitivity through deep block analysis provides valuable new ideas and methods for research and practice in this domain.
